{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test is based upon `oarphpy_test/test_spark.py#test_spark_with_custom_library()` with small modifications to run in a Jupyter notebook.  You can run this notebook by itself using:\n",
    "```\n",
    "jupyter-nbconvert \\\n",
    "            --ExecutePreprocessor.timeout=3600 \\\n",
    "              --to notebook --execute --output /tmp/out \\\n",
    "                test_spark_ships_custom_library_in_notebook.ipynb\n",
    "```\n",
    "\n",
    "The notebook assumes that `oarphpy` and Spark are installed in the system / Jupyter kernel environment.  You can do that yourself using \n",
    "```\n",
    "pip install oarphpy[spark]\n",
    "```\n",
    "(You may need to also install Java).\n",
    "\n",
    "First, use the notebook to create a local python module we'd like to ship with our spark jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/test_spark_ships_custom_library_in_notebook || true\n",
    "!mkdir -p /tmp/test_spark_ships_custom_library_in_notebook\n",
    "import os; os.chdir('/tmp/test_spark_ships_custom_library_in_notebook')\n",
    "!mkdir -p my_src_root/mymodule\n",
    "!touch my_src_root/mymodule/__init__.py\n",
    "!echo \"pi = 3.14\" > my_src_root/mymodule/foo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the local module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd my_src_root && $(which python || which python3) -c 'from mymodule.foo import pi; print(pi)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and start the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from oarphpy.spark import NBSpark\n",
    "NBSpark.SRC_ROOT = '/tmp/test_spark_ships_custom_library_in_notebook/my_src_root/mymodule'\n",
    "spark = NBSpark.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test that the module gets shipped with the job in an egg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_lib():\n",
    "    # Make sure `mymodule` is not on the default local PYTHONPATH\n",
    "    import os\n",
    "    os.chdir('/tmp')\n",
    "    \n",
    "    import re\n",
    "    import mymodule\n",
    "\n",
    "    # The module should come from the included egg\n",
    "    imp_path = mymodule.__file__\n",
    "    assert re.match(\n",
    "      r'^(.*)spark-(.*)/mymodule-0\\.0\\.0-py(.+)\\.egg/mymodule/__init__\\.py$',\n",
    "      imp_path)\n",
    "\n",
    "    # Now verify the module itself\n",
    "    from mymodule import foo\n",
    "    assert foo.pi == 3.14\n",
    "    \n",
    "    return True\n",
    "  \n",
    "# Now test that the lib gets egg-ified and shipped as a SparkFile\n",
    "from oarphpy import spark as S\n",
    "res = S.for_each_executor(spark, lambda: test_my_lib())\n",
    "assert res and all(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NBSpark` supports live library code edits (without restarting the kernel or Spark session).  Test that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"bar = 'baz'\" > my_src_root/mymodule/foo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_lib2():\n",
    "    # Make sure `mymodule` is not on the default local PYTHONPATH\n",
    "    import os\n",
    "    os.chdir('/tmp')\n",
    "    \n",
    "    import re\n",
    "    import mymodule\n",
    "\n",
    "    # The module should come from the included egg\n",
    "    imp_path = mymodule.__file__\n",
    "    assert re.match(\n",
    "      r'^(.*)spark-(.*)/mymodule-0\\.0\\.0-py(.+)\\.egg/mymodule/__init__\\.py$',\n",
    "      imp_path)\n",
    "\n",
    "    # Now verify the module itself\n",
    "    from mymodule import foo\n",
    "    assert foo.bar == 'baz'\n",
    "    \n",
    "    return True\n",
    "  \n",
    "# Now test that the updated lib is there\n",
    "res = S.for_each_executor(spark, lambda: test_my_lib2())\n",
    "assert res and all(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
