{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peering inside Histogram Bins: Histograms with Examples via Spark and Bokeh\n",
    "\n",
    "<img src=\"https://github.com/pwais/oarphpy/blob/master/oarphpy_test/fixtures/test_histogram_with_examples_2_demo_click.png?raw=true\" alt=\"hist-with-examples\" style=\"width: 500px;\"/>\n",
    "\n",
    "A histogram is one of the most effective tools for exploring a new dataset.  In one graph, a histogram displays key information about the data's mean, variance, outliers, and periodic features.  Histograms are so important than several libraries make histogramming extremely easy:\n",
    " * In [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html), the user can immediately plot a histogram from a Dataframe in a Jupyter notebook with a single function call.\n",
    " * [Tensorboard](https://github.com/tensorflow/tensorboard/blob/master/docs/r1/histograms.md) features a powerful temporal histogramming tool that can be critical for monitoring the weights of neural networks during training and debugging high-dimensional optimization problems.\n",
    " * [Bokeh](https://demo.bokeh.org/selection_histogram) provides a web-based histogram plotter with interactive tools and a nice Python API.\n",
    "\n",
    "Histogram plots are often both surprising and boring: some bins have more items than expected, some bins have fewer, and a lot of bins are empty.  It's not unreasonable to immediately want to ask: can we peer inside a bin?  Which examples from my dataset are actually in there?  And, since this histogram only shows one dimension of the data, what might be some other dimensions or factors that are common among most of the things in that bin?\n",
    "\n",
    "This tutorial will show you how OarphPy's `HistogramWithExamplesPlotter` helps you do exactly that!  What do you need?\n",
    " 1. A DataFrame (Pandas or Spark) with at least one numeric or categorical column.\n",
    " 2. A Python function for visualizing a row (or some portion of a row).  For example, a function to convert a row to a pretty string or HTML visualization.\n",
    " 3. A Jupyter Notebook (like this one!) or a Python script to render the Bokeh HTML plot and display and/or save it to disk.\n",
    "\n",
    "Why `HistogramWithExamplesPlotter` ?\n",
    " * We'll use Spark to compute the actual histogram.  Spark provides multi-cpu (and even multi-machine) processing to make histogramming scale linearly.\n",
    " * We'll also use Spark to render visualizations for the bucket items.  Spark's RDD API helps accomodate arbitrary user visualization functions and runs computation in parallel (even across many machines).\n",
    " * We use Bokeh's Histogram tool because it supports the simple interactivity we need (click on a bucket to view examples) and plots work in any modern browser with no extra dependencies.\n",
    "\n",
    "\n",
    "## A Motivating Example: Exploring Out-of-Distribution Robustness in MNIST\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3744/1*SGPGG7oeSvVlV5sOSQ2iZw.png\" width=\"600\" />\n",
    "\n",
    "The [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset is well-studied in Computer Vision and consists of thousands of small pictures of hand-written digits.  (New to MNIST? Suppose you're the Post Office and you want to train a Computer Vision model that can read the zipcode digits that people write on their mail.  MNIST has a sample of such handwritten digits).  Today, it's easy to train a convolutional neural network on MNIST and achieve over 98% accuracy.  We're going to do exactly that in the next notebook cell!  \n",
    "\n",
    "But MNIST is a relatively small dataset versus all the digits people have ever written on paper.  How robust is a trained MNIST model to new data?  What if we don't have labels for that new data?  In this tutorial, we're going to use `HistogramWithExamplesPlotter` to examine the scores that an MNIST-trained model gives to \"corrupted\" data never seen at training time.\n",
    "\n",
    "First, let's train a basic MNIST model using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic MNIST ConvNet c/o Keras\n",
    "# https://keras.io/examples/vision/mnist_convnet/\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the trained model on the test set and pack the predictions into a Pandas DataFrame.  For each input, the network outputs a score for each class (the numbers 0 through 9).  We'll take a look at the raw network scores for the class \"7,\" which is easy to confused for a \"1\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "rows = []\n",
    "for i, (x_i, pred_i) in enumerate(zip(x_test, predictions)):\n",
    "    row = {}\n",
    "    for classname, score in enumerate(pred_i):\n",
    "        row[f'score_{classname}'] = score\n",
    "    row['x_i'] = x_i.tolist()\n",
    "    rows.append(row)\n",
    "\n",
    "import pandas as pd\n",
    "prediction_df = pd.DataFrame(rows)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's histogram the network's scores for the 7 class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "prediction_df['score_7'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /opt && (git clone https://github.com/google-research/mnist-c || echo \"have mnist-c\")\n",
    "import sys\n",
    "sys.path.append('/opt/mnist-c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wand\n",
    "!ln -s /opt/mnist-c/pessimal_noise_matrix ./pessimal_noise_matrix || echo \"symlink placed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corruptions\n",
    "\n",
    "# x_corrupted = corruptions.speckle_noise(x_test[100] * 255)\n",
    "# x_corrupted = corruptions.speckle_noise(x_test[100] * 255)\n",
    "x_corrupted = corruptions.glass_blur(x_test[100] * 255, severity=4)\n",
    "x_corrupted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oarphpy.plotting import img_to_img_tag\n",
    "\n",
    "img_html = img_to_img_tag(x_corrupted)\n",
    "\n",
    "def show_html(html):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(html))\n",
    "show_html(img_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tqdm\n",
    "from tqdm import tqdm\n",
    "x_test_c = np.zeros_like(x_test)\n",
    "for i in tqdm(range(len(x_test_c))):\n",
    "#     xform = corruptions.glass_blur\n",
    "    xform = corruptions.rotate\n",
    "    x_test_c[i] = (1. / 255) *xform(x_test[i] * 255, severity=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_c = model.predict(x_test_c)\n",
    "rows = []\n",
    "for i, (x_i, pred_i) in enumerate(zip(x_test_c, predictions_c)):\n",
    "    row = {}\n",
    "    for classname, score in enumerate(pred_i):\n",
    "        row[f'score_{classname}'] = score\n",
    "    row['x_i'] = x_i.tolist()\n",
    "    rows.append(row)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "prediction_c_df = pd.DataFrame(rows)\n",
    "prediction_c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_c_df['score_7'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oarphpy.spark import NBSpark\n",
    "\n",
    "spark = NBSpark.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import show as bokeh_show\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from oarphpy import plotting as pl\n",
    "class MyPlotter(pl.HistogramWithExamplesPlotter):\n",
    "    NUM_BINS = 20\n",
    "    def display_bucket(self, sub_pivot, bucket_id, irows):\n",
    "        MAX_TO_VIZ = 150\n",
    "        \n",
    "        from oarphpy.plotting import img_to_img_tag\n",
    "        htmls = []\n",
    "        for row in irows:\n",
    "            x_i = np.array(row['x_i'])\n",
    "            img_html = img_to_img_tag(x_i)\n",
    "            htmls.append(img_html)\n",
    "            \n",
    "            if len(htmls) > MAX_TO_VIZ:\n",
    "                break\n",
    "        \n",
    "        # Make a nice table\n",
    "        N_COLS = 25\n",
    "        from oarphpy.util import ichunked\n",
    "        trs = [\n",
    "            \"<tr>%s</tr>\" % ''.join(\"<td>%s</td>\" % ihtml for ihtml in row)\n",
    "            for row in ichunked(htmls, n=N_COLS) \n",
    "        ]\n",
    "        table_html = \"<table>%s</table>\" % ''.join(trs)\n",
    "        \n",
    "        return bucket_id, table_html\n",
    "\n",
    "plotter = MyPlotter()\n",
    "fig = plotter.run(spark.createDataFrame(prediction_c_df), 'score_7')\n",
    "bokeh_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotter.run(spark.createDataFrame(prediction_c_df), 'score_1')\n",
    "bokeh_show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples of `HistogramWithExamplesPlotter` https://drive.google.com/drive/folders/1dOmkPvdFiGBMaYEddx1KK5vmCeYl2CyV?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotter.run(spark.createDataFrame(prediction_df), 'score_7')\n",
    "bokeh_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
